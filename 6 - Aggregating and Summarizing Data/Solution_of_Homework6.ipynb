{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAM9KLH_OdrR"
      },
      "source": [
        "# Homework # 6: Spark DataFrames Exercise (Solutions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHAjU3isOdrU"
      },
      "source": [
        "#### Use the walmart_stock.csv file to Answer and complete the  tasks below!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL__xu4MOdrU"
      },
      "source": [
        "#### Start a simple Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "Wzwuz7b2OdrV"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('Solution').getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWGXMwZiOdrV"
      },
      "source": [
        "#### Load the Walmart Stock CSV File from URL (https://raw.githubusercontent.com/oakabc/DEA/refs/heads/main/6%20-%20Aggregating%20and%20Summarizing%20Data/walmart_stock.csv)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "4dm_3X1OOdrV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02bbbd42-796d-4b17-f71e-8c86f777e07b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded as walmart_stock.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Date: date, Open: double, High: double, Low: double, Close: double, Volume: int, Adj Close: double]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "# Define the URL and the local file path\n",
        "url = \"https://raw.githubusercontent.com/oakabc/DEA/refs/heads/main/6%20-%20Aggregating%20and%20Summarizing%20Data/walmart_stock.csv\"\n",
        "local_file = \"walmart_stock.csv\"\n",
        "# Download the file\n",
        "response = requests.get(url)\n",
        "if response.status_code == 200:\n",
        "   with open(local_file, \"wb\") as f:\n",
        "       f.write(response.content)\n",
        "   print(f\"File downloaded as {local_file}\")\n",
        "else:\n",
        "   print(\"Failed to download the file\")\n",
        "\n",
        "df = spark.read.csv(local_file, header=True, inferSchema = True)\n",
        "df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFLZ-11oOdrV"
      },
      "source": [
        "#### What are the column names?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Xd4NMjuNOdrW",
        "outputId": "d2af2b94-7080-4737-e3f9-a52d72ac8227",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ6J9QGCOdrW"
      },
      "source": [
        "#### What does the Schema look like?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NzAVoLw_OdrW",
        "outputId": "f3bb57e3-5e04-4fc9-a083-a20c216fba06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Date: date (nullable = true)\n",
            " |-- Open: double (nullable = true)\n",
            " |-- High: double (nullable = true)\n",
            " |-- Low: double (nullable = true)\n",
            " |-- Close: double (nullable = true)\n",
            " |-- Volume: integer (nullable = true)\n",
            " |-- Adj Close: double (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqd3ci3POdrX"
      },
      "source": [
        "#### Print out the first 5 columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AOUdHHvbOdrX",
        "outputId": "2ec115a2-a339-4c8d-8951-4975e218cce0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row(Date=datetime.date(2012, 1, 3), Open=59.970001, High=61.060001, Low=59.869999, Close=60.330002, Volume=12668800, Adj Close=52.619234999999996)\n",
            "\n",
            "\n",
            "Row(Date=datetime.date(2012, 1, 4), Open=60.209998999999996, High=60.349998, Low=59.470001, Close=59.709998999999996, Volume=9593300, Adj Close=52.078475)\n",
            "\n",
            "\n",
            "Row(Date=datetime.date(2012, 1, 5), Open=59.349998, High=59.619999, Low=58.369999, Close=59.419998, Volume=12768200, Adj Close=51.825539)\n",
            "\n",
            "\n",
            "Row(Date=datetime.date(2012, 1, 6), Open=59.419998, High=59.450001, Low=58.869999, Close=59.0, Volume=8069400, Adj Close=51.45922)\n",
            "\n",
            "\n",
            "Row(Date=datetime.date(2012, 1, 9), Open=59.029999, High=59.549999, Low=58.919998, Close=59.18, Volume=6679300, Adj Close=51.616215000000004)\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# df.head(5) # in messy format\n",
        "\n",
        "for row in df.head(5):\n",
        "  print(row)\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2RcakD1OdrX"
      },
      "source": [
        "#### Use describe() to learn about the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Pmh7cubmOdrX",
        "outputId": "adb01e8f-3699-449c-eb5c-ce3f3b84ad28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "|summary|              Open|             High|              Low|            Close|           Volume|        Adj Close|\n",
            "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "|  count|              1258|             1258|             1258|             1258|             1258|             1258|\n",
            "|   mean| 72.35785375357709|72.83938807631165| 71.9186009594594|72.38844998012726|8222093.481717011|67.23883848728146|\n",
            "| stddev|  6.76809024470826|6.768186808159218|6.744075756255496|6.756859163732991|  4519780.8431556|6.722609449996857|\n",
            "|    min|56.389998999999996|        57.060001|        56.299999|        56.419998|          2094900|        50.363689|\n",
            "|    max|         90.800003|        90.970001|            89.25|        90.470001|         80898100|84.91421600000001|\n",
            "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.describe().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWYKl7FXOdrX"
      },
      "source": [
        "## Bonus Question!\n",
        "#### There are too many decimal places for mean and stddev in the describe() dataframe. Format the numbers to just show up to two decimal places. Pay careful attention to the datatypes that .describe() returns, we didn't cover how to do this exact formatting, but we covered something very similar. [Check this link for a hint](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.Column.cast.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvVScp8XOdrX"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jkdc5SboOdrX",
        "outputId": "3aa949cb-4438-496b-a8e2-ca6e45c843da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- summary: string (nullable = true)\n",
            " |-- Open: string (nullable = true)\n",
            " |-- High: string (nullable = true)\n",
            " |-- Low: string (nullable = true)\n",
            " |-- Close: string (nullable = true)\n",
            " |-- Volume: string (nullable = true)\n",
            " |-- Adj Close: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.describe().printSchema() # All columns are string format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "id": "JR67gnGWOdrY"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import format_number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "SReSTC4mOdrY",
        "outputId": "28f2ac2e-479a-4321-8e72-fa5edbe3d337",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "|summary|              Open|             High|              Low|            Close|           Volume|        Adj Close|\n",
            "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "|  count|              1258|             1258|             1258|             1258|             1258|             1258|\n",
            "|   mean| 72.35785375357709|72.83938807631165| 71.9186009594594|72.38844998012726|8222093.481717011|67.23883848728146|\n",
            "| stddev|  6.76809024470826|6.768186808159218|6.744075756255496|6.756859163732991|  4519780.8431556|6.722609449996857|\n",
            "|    min|56.389998999999996|        57.060001|        56.299999|        56.419998|          2094900|        50.363689|\n",
            "|    max|         90.800003|        90.970001|            89.25|        90.470001|         80898100|84.91421600000001|\n",
            "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result = df.describe()\n",
        "result.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.select(result['summary'],\n",
        "              format_number(result['Open'].cast('float'),2).alias('Open'),\n",
        "              format_number(result['High'].cast('float'),2).alias('High'),\n",
        "              format_number(result['Low'].cast('float'),2).alias('Low'),\n",
        "              format_number(result['Close'].cast('float'),2).alias('Close'),\n",
        "              result['Volume'].cast('int').alias('Volume')\n",
        "              ).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rX3w5jMR3dH",
        "outputId": "bc37c7ae-082f-44f1-997d-efc8fdf1535d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+--------+--------+--------+--------+\n",
            "|summary|    Open|    High|     Low|   Close|  Volume|\n",
            "+-------+--------+--------+--------+--------+--------+\n",
            "|  count|1,258.00|1,258.00|1,258.00|1,258.00|    1258|\n",
            "|   mean|   72.36|   72.84|   71.92|   72.39| 8222093|\n",
            "| stddev|    6.77|    6.77|    6.74|    6.76| 4519780|\n",
            "|    min|   56.39|   57.06|   56.30|   56.42| 2094900|\n",
            "|    max|   90.80|   90.97|   89.25|   90.47|80898100|\n",
            "+-------+--------+--------+--------+--------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5E-QyulsOdrY"
      },
      "source": [
        "#### Create a new dataframe with a column called HV Ratio that is the ratio of the High Price versus volume of stock traded for a day."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "7_MRWOJnOdrY",
        "outputId": "f2dbbd3d-ed57-4849-f96e-b1e807ddfdaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|            HV Ratio|\n",
            "+--------------------+\n",
            "|4.819714653321546E-6|\n",
            "|6.290848613094555E-6|\n",
            "|4.669412994783916E-6|\n",
            "|7.367338463826307E-6|\n",
            "|8.915604778943901E-6|\n",
            "|8.644477436914568E-6|\n",
            "|9.351828421515645E-6|\n",
            "| 8.29141562102703E-6|\n",
            "|7.712212102001476E-6|\n",
            "|7.071764823529412E-6|\n",
            "|1.015495466386981E-5|\n",
            "|6.576354146362592...|\n",
            "| 5.90145296180676E-6|\n",
            "|8.547679455011844E-6|\n",
            "|8.420709512685392E-6|\n",
            "|1.041448341728929...|\n",
            "|8.316075414862431E-6|\n",
            "|9.721183814992126E-6|\n",
            "|8.029436027707578E-6|\n",
            "|6.307432259386365E-6|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df2 = df.withColumn(\"HV Ratio\", df['High']/df['Volume'])\n",
        "df2.select('HV Ratio').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBNV4tDCOdrY"
      },
      "source": [
        "#### What day had the Peak High in Price?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "cosOWPj8OdrY",
        "outputId": "99a91c8d-3fdd-4f24-fb34-d638518d720e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datetime.date(2015, 1, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "df.orderBy(df['High'].desc()).head(1)[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5zS3COkOdrY"
      },
      "source": [
        "#### What is the mean of the Close column?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "IURofKAjOdrY",
        "outputId": "4250fa7d-5954-4560-80e3-0f115c10de6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+\n",
            "|    Average Close|\n",
            "+-----------------+\n",
            "|72.38844998012726|\n",
            "+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import mean, avg\n",
        "df.select(avg('Close').alias('Average Close')).show() # you can also use mean\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlLnHc6aOdrY"
      },
      "source": [
        "#### What is the max and min of the Volume column?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "collapsed": true,
        "id": "LMGZQopjOdrY"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import max, min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "_fBx81qHOdrY",
        "outputId": "e444cfd6-8298-4761-9896-12c0053268c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+\n",
            "|max(Volume)|min(Volume)|\n",
            "+-----------+-----------+\n",
            "|   80898100|    2094900|\n",
            "+-----------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.select(max('Volume'), min('Volume')).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhBdzqAjOdrY"
      },
      "source": [
        "#### How many days was the Close lower than 60 dollars?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import count\n",
        "result = df.filter(df['Close']<60)\n",
        "result.select(count('Close')).show() # Return DataFrame content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU8fQnU1azu2",
        "outputId": "4a496ae3-9c55-47d5-b04f-0837c805b567"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+\n",
            "|count(Close)|\n",
            "+------------+\n",
            "|          81|\n",
            "+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "e5-qtHpkOdrZ",
        "outputId": "ec3a17b1-54fc-4358-b8f2-3ef779134aa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "df.filter('Close < 60').count() #PySpark-SQL like Syntax\n",
        "# df.filter(df['Close] < 60 ).count() # Python column expression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQTh4xl_OdrZ"
      },
      "source": [
        "#### What percentage of the time was the High greater than 80 dollars ?\n",
        "#### In other words, (Number of Days High>80)/(Total Days in the dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Ux5OHX-uOdrZ",
        "outputId": "cbeeda91-eddb-4f68-903a-bdc8ff2084f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.141494435612083"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "(df.filter(df['High'] > 80).count()/ df.count()) * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNyEE-4nOdrZ"
      },
      "source": [
        "#### What is the Pearson correlation between High and Volume?\n",
        "#### [Hint](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.stat.Correlation.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "f_9aPqdjOdrZ",
        "outputId": "e1d7d90e-6761-4f9f-be84-fb078759d8cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+\n",
            "| corr(High, Volume)|\n",
            "+-------------------+\n",
            "|-0.3384326061737161|\n",
            "+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import corr\n",
        "df.select(corr('High','Volume')).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czgJvkoEOdrZ"
      },
      "source": [
        "#### What is the max High per year?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "nVmzQmgtOdrZ",
        "outputId": "0cc5e35a-13bb-4399-e0ff-3a1162ec584b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---------+\n",
            "|Year|max(High)|\n",
            "+----+---------+\n",
            "|2015|90.970001|\n",
            "|2013|81.370003|\n",
            "|2014|88.089996|\n",
            "|2012|77.599998|\n",
            "|2016|75.190002|\n",
            "+----+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import year\n",
        "yeardf = df.withColumn(\"Year\",year(df['Date']))\n",
        "max_df = yeardf.groupBy('Year').max()\n",
        "max_df.select('Year', 'max(High)').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykIRPJ2VOdrZ"
      },
      "source": [
        "#### What is the average Close for each Calendar Month?\n",
        "#### In other words, across all the years, what is the average Close price for Jan,Feb, Mar, etc... Your result will have a value for each of these months."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "YnKTZ9GhOdrZ",
        "outputId": "1249322a-93ae-48e1-96bd-bab8f6f57492",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------------+\n",
            "|Month|       avg(Close)|\n",
            "+-----+-----------------+\n",
            "|    1|71.44801958415842|\n",
            "|    2|  71.306804443299|\n",
            "|    3|71.77794377570092|\n",
            "|    4|72.97361900952382|\n",
            "|    5|72.30971688679247|\n",
            "|    6| 72.4953774245283|\n",
            "|    7|74.43971943925233|\n",
            "|    8|73.02981855454546|\n",
            "|    9|72.18411785294116|\n",
            "|   10|71.57854545454543|\n",
            "|   11| 72.1110893069307|\n",
            "|   12|72.84792478301885|\n",
            "+-----+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import month\n",
        "monthdf = df.withColumn('Month', month('Date'))\n",
        "monthavgs = monthdf.select('Month','Close').groupBy('Month').mean()\n",
        "monthavgs.select('Month','avg(Close)').orderBy('Month').show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jtasmxr6OdrZ"
      },
      "source": [
        "# Merry Christmas and Happy New Year !"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [conda root]",
      "language": "python",
      "name": "conda-root-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}